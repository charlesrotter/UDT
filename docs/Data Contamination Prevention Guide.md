**Data Contamination Prevention Guide for Temporal Framework** **Testing**

üö®** Critical Protocol: Avoiding Model-Contaminated Data** When testing your temporal framework against standard models, using data that has already been processed through one of the models creates circular reasoning and invalid comparisons. This guide identifies **raw vs. contaminated data** for both SPARC and Pantheon\+ datasets. 

üìä** SPARC Database \(Galaxy Rotation Curves\)**

‚úÖ** **RAW DATA \(Use These\):

**V\_obs\(R\) **: Observed rotation velocities \(km/s\) *Source*: Direct HI/HŒ± spectroscopy

*Status*: Model-independent kinematics *Use*: Primary dependent variable for fitting **R **: Galactocentric radius \(kpc\)

*Source*: Angular position √ó distance *Caution*: Check distance source \(see below\) *Use*: Independent variable

**err\_V **: Velocity measurement uncertainties *Source*: Instrumental/statistical errors *Status*: Observational uncertainty

*Use*: Fitting weights

**Spitzer 3.6Œºm surface brightness**:

*Source*: Direct infrared photometry

*Status*: Raw stel ar light distribution *Use*: For baryonic mass estimates

‚ö†** **PROCESSED DATA \(Check Assumptions\): **Galaxy distances**:

*Method 1*: Hubble flow ‚Üí **CONTAMINATED** \(assumes H‚ÇÄ\) *Method 2*: TRGB, Cepheids ‚Üí **CLEAN** \(geometric\)

*Method 3*: Group membership ‚Üí **CLEAN** \(kinematic\) *Action*: Use only geometric/kinematic distances OR back-calculate raw data **Stellar masses M\_\* **:

*Assumption*: Mass-to-light ratio Œ•‚Çä

*Standard*: Œ•‚Çä ‚âà 0.5 M‚òâ/L‚òâ \(population synthesis\) *Action*: Verify assumptions or use raw photometry

‚ùå** **CONTAMINATED DATA \(Never Use\):

**V\_bar/V\_obs ** ratios

*Contamination*: Pre-calculated using assumed distance \+ cosmology *Problem*: Circular reasoning for model comparison **Dark matter fractions**

*Contamination*: Assumes baryonic mass models *Problem*: Prejudges outcome of dark matter test **Absolute magnitudes**

*Contamination*: Distance-dependent

*Problem*: Imports cosmological assumptions

üåü** Pantheon\+ Database \(Type Ia Supernovae\)**

‚úÖ** **RAW DATA \(Use These\):

**z\_helio **: Heliocentric redshift

*Source*: Direct spectroscopy \(host or SN\) *Status*: Doppler shift measurement

*Use*: Convert to CMB frame kinematical y **z\_cmb **: CMB frame redshift

*Source*: z\_helio \+ kinematic corrections *Status*: Corrected for solar/galactic motion only *Use*: Primary independent variable

**m\_b\_corrected **: Peak B-band apparent magnitude *Source*: Light curve photometry

*Processing*: K-corrections, galactic extinction

*Status*: Observational magnitude *Use*: Primary dependent variable

**x1 , c **: SALT2 light curve parameters *Source*: Light curve shape and color *Status*: Empirical standardization parameters *Use*: Magnitude corrections \(if needed\)

‚ö†** **PROCESSED DATA \(Check Assumptions\): **Distance modulus Œº **:

*Calculation*: Often pre-calculated using ŒõCDM

*Clean version*: Œº = m\_B - M\_B \(if M\_B assumed\) *Action*: Recalculate from raw magnitudes **Peculiar velocity corrections**:

*Assumption*: Velocity field model

*Impact*: Usual y smal \(<0.01 in z\) *Action*: Use uncorrected z or verify method

‚ùå** **CONTAMINATED DATA \(Never Use\):

**d\_L **: Luminosity distance

*Contamination*: Calculated assuming ŒõCDM cosmology *Problem*: Circular for cosmological model comparison **Hubble residuals**:

*Contamination*: Deviation from ŒõCDM fit *Problem*: Pre-assumes ŒõCDM as baseline **mu\_model **: Model-predicted distance modulus *Contamination*: From specific cosmological model *Problem*: Cannot test model against its own predictions

üîÑ** **Data Recovery Strategies

**Reverse-Engineering Clean Data:**

1. **SPARC Distance Recovery**:

python

*\# If distance assumed H‚ÇÄ = 70 km/s/Mpc:* z\_assumed = d\_Mpc \* 70 / 299792.458

*\# Check against actual redshift to verify* 2. **Pantheon\+ Raw Magnitude Recovery**: python

*\# If only distance modulus available:*

m\_b\_raw = mu \+ M\_B\_assumed

*\# Verify against light curve photometry* 3. **Cross-Validation**:

Compare multiple data sources

Check internal consistency

Verify against original papers

üéØ** **Testing Protocol

**Identical Input Data:**

1. **Extract identical raw datasets** for both models 2. **Apply identical quality cuts**

3. **Use identical error estimates**

4. **Apply identical systematic corrections** \(if any\) **Model Fitting:**

1. **Temporal Framework**:

Fit œÑ\(r\) = R‚ÇÄ/\(R‚ÇÄ \+ r\) directly to raw data Extract R‚ÇÄ, enhancement factors

2. **Standard Models**:

Fit ŒõCDM/NFW to same raw data

Extract H‚ÇÄ, Œ©‚Çò, dark matter parameters

3. **Comparison**:

œá¬≤ statistics on identical datasets

AIC/BIC for model complexity

Residual analysis

‚ö°** **Quick Contamination Checklist Before using any data point, ask:

Is this a direct observational measurement? 

What assumptions went into processing this data? 

Was a cosmological model used in the calculation? 

Can I trace back to the raw observable? 

Am I testing a model against its own assumptions? 

**Red Flags:**

Any quantity labeled "model-dependent" 

Pre-calculated cosmological distances

"Standard" values without uncertainty ranges Data that seems "too good" for the claimed precision Missing details about processing pipeline

üìà** **Statistical Validation

**Sample Size Requirements:**

**SPARC**: 175 galaxies ‚Üí Use al for maximum statistics **Pantheon\+**: 1701 SNe ‚Üí Use ful sample across z = 0.001-2.2

**Quality Metrics:**

**Success rate**: % of successful fits

**œá¬≤/dof**: Goodness of fit per degree of freedom **RMS residuals**: Scatter around best fit **Systematic trends**: Residuals vs. observational parameters **Model Comparison:**

**Œîœá¬≤**: Direct statistical comparison

**AIC/BIC**: Penalized for model complexity **Cross-validation**: Train/test splits

**Blind analysis**: Process both models identical y

üèÜ** **Success Criteria

Your temporal framework demonstrates superiority if: 1. **Statistical**: Œîœá¬≤ > 9 \(3œÉ preference\) on large samples 2. **Systematic**: No remaining trends in residuals 3. **Physical**: Unified scale hierarchy \(R‚ÇÄ galactic ‚Üí R‚ÇÄ cosmic\) 4. **Predictive**: Success on independent datasets 5. **Robust**: Consistent across data subsamples Remember: **Extraordinary claims require extraordinary evidence**. The more careful you are about data quality and contamination, the stronger your eventual publication wil be.



