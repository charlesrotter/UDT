Thanks for clarifying. I'll look for publicly accessible datasets and
experimental results from particle accelerators, interferometry
experiments, and quantum optics that could be used to validate or
challenge new space-time geometries in the quantum realm. I'll
prioritize sources that include anomalous or unexplained behavior. I'll
update you once I've gathered the relevant information.

**Datasets Probing Quantum Space-Time Geometry in the Quantum Realm**

**Particle Accelerators: High-Energy Collision Data and Anomalies**

- **CERN LHC Open Data Portal (ATLAS & CMS)** -- CERN provides public
  access to petabytes of LHC collision data for research and education.
  For example, the ATLAS Open Data release includes 13 TeV
  proton--proton collision datasets (and even heavy-ion collisions)
  under a CC0 license. These datasets allow independent researchers to
  search for exotic phenomena. One target has been **microscopic black
  holes** or effects of extra spatial dimensions. The CMS experiment
  performed dedicated searches for mini black hole signatures in 7 TeV
  collisions; **no evidence was found**, excluding such black holes up
  to masses of about 4 TeV in several extra-dimension models. This null
  result constrains theories that unify quantum mechanics and gravity
  via "curled-up" extra dimensions. LHC data have also been mined for
  other anomalies -- e.g. **excesses in collision events** -- but so
  far, observed collision patterns are consistent with the Standard
  Model within statistical limits (notwithstanding transient anomalies
  that later resolved with more data). Notably, the LHC's high-precision
  measurements can even test fundamental symmetry: a recent analysis of
  LHC Run-2 **prompt photon** data set stringent new limits on **Lorentz
  invariance violation**. Photons with energies up to 2.5 TeV showed no
  deviations from special relativity, improving prior collider bounds on
  isotropic Lorentz-violation parameters by a factor \~55. All told, the
  LHC's open datasets serve as a proving ground for novel space-time
  phenomena -- enabling searches for quantum gravity effects (like extra
  dimensions or Lorentz symmetry breaking) and providing **publicly
  accessible data** to challenge or validate such new theories.

- **Fermilab High-Energy Experiments (Tevatron & Muon g-2)** -- While
  Fermilab's Tevatron collider is now retired, its data (e.g. from CDF
  and DØ experiments) have been archived and in some cases made
  available for public or academic analysis. These inform studies of
  high-energy collisions at \~2 TeV, complementary to the LHC. In
  addition, Fermilab leads unique experiments that test fundamental
  physics in other ways. A prime example is the **Muon g-2 experiment**,
  which measures the magnetic moment ("g-factor") of the muon to extreme
  precision. The **2021 Muon g-2 results** showed muons "wobbling"
  faster than predicted by quantum field theory (Standard Model) -- a
  **4.2σ deviation** suggesting undiscovered influences. This is a
  **publicly reported dataset** (with results published in *Physical
  Review Letters* and detailed in Fermilab's public releases) that hints
  at physics beyond the Standard Model. If this discrepancy holds up
  with more data (runs are ongoing), it could imply new fields or a
  breakdown of our current quantum field theory -- an intriguing clue
  from the quantum realm that something about space-time at quantum
  scales (or new particles in it) is not fully understood. All raw data
  aren't immediately open in real-time, but the **result datasets and
  analysis** are published for scrutiny, and combined with Brookhaven's
  earlier data they strengthen the case that muons are sensing
  "something not in our best theory".

*Data Access:* The above accelerator-related datasets and results can be
accessed through official portals. CERN's Open Data portal houses LHC
collision events (with software tools to analyze them). Published
analyses (e.g. for Lorentz symmetry tests or the muon *g-2* result) are
available via journals or lab websites (often with supplemental data).
These high-energy datasets enable researchers to **probe space-time at
tiny distances and high energies**, testing ideas like extra dimensions,
quantum gravity, and Lorentz invariance in a laboratory setting.

**Precision Interferometry: Probing Space-Time Fluctuations and
Relativity**

- **LIGO/Virgo Gravitational-Wave Data** -- Modern interferometric
  observatories like LIGO and Virgo provide open datasets on
  gravitational waves that can test general relativity and potential
  space-time deviations. The **Gravitational-Wave Open Science Center
  (GWOSC)** releases all detected event data and even strain time-series
  for public analysis. By analyzing these data, one can investigate
  whether gravitational waves propagate as Einstein's theory predicts or
  if there are anomalies indicating new physics. A landmark result came
  with the binary neutron star merger GW170817 (public data available on
  GWOSC): LIGO/Virgo saw gravitational waves *and* satellites saw a
  gamma-ray burst from the same event. The **arrival times differed by
  only \~1.7 s** despite traveling \~130 million light-years. This
  places a **striking limit on Lorentz invariance violation** -- the
  speed of gravity was found to equal the speed of light to within parts
  in 10\^15. In other words, LIGO data showed no dispersion or timing
  lag that would hint at quantum structure of space-time; gravitational
  waves adhered to relativity's expectations (no frequency-dependent
  speed and no detectable mass for the graviton, with a graviton mass
  bound \~10\^−22 eV from LIGO/Virgo). Ongoing public LIGO data is also
  being combed for unexplained signals: for instance, searches for a
  stochastic background of space-time "foam" or quantum gravitational
  noise. So far, **LIGO noise spectra have shown no unknown periodic
  fluctuations** beyond instrumental/systematic effects -- placing
  constraints on certain holographic space-time models. All LIGO
  observation runs (O1, O2, O3, etc.) are publicly available, so
  independent researchers can look for subtle anomalies (e.g.
  hypothetical gravitational wave "echoes" after black hole mergers that
  some quantum gravity theories predict). No conclusive echoes have been
  confirmed in the open data, but analyses continue. **Bottom line:**
  LIGO's open datasets have overwhelmingly **validated standard General
  Relativity**, while providing new avenues to test quantum space-time
  theories under extreme conditions (merging black holes/neutron stars).
  Any deviation (such as frequency-dependent speed or unexpected
  signals) would be a major discovery -- none observed yet, but the data
  are there for anyone to challenge prevailing theory.

- **Holometer and Space-Time "Pixelation" Searches** -- At Fermilab, the
  Holometer was a pair of high-precision 40 m interferometers designed
  specifically to detect hypothesized *Planck-scale space-time
  fluctuations*. This experiment looked for correlated noise between the
  two laser interferometers that could indicate a fundamental
  discreteness ("holographic noise") in space and time. Over a year of
  data (which has been published in open-access papers) yielded a clear
  result: **no evidence of the predicted holographic jitter** was seen
  at the sensitivity of the instrument. The Holometer ruled out one
  specific model of a "pixelated universe" (proposed by Craig Hogan) at
  high statistical significance. In simple terms, if space-time were
  made of tiny indivisible units at the Planck scale, the Holometer data
  should have recorded an irreducible noise floor as space jittered.
  Instead, after subtracting all known sources of noise, no excess
  remained -- implying that if space-time is discrete, it must be at
  scales finer (or in patterns more complex) than the experiment could
  detect. This null result, publicly reported in 2015, **challenges that
  particular quantum geometry model** but also demonstrates that we now
  have instruments capable of probing **unprecedented scales (down to
  10\^−19 m)** in space-time structure. The Holometer team has made
  their results public (e.g. via arXiv and Fermilab reports), and the
  techniques serve as a template for future experiments. Relatedly,
  modern Michelson--Morley-type experiments with optical cavities also
  continue to test the smoothness of space-time -- recent resonator
  tests showed no "aether wind" or Lorentz-violating effect at the
  10\^−17 level, reaffirming continuous space-time and isotropic light
  speed to extraordinary precision.

- **Atom Interferometers and Clock Tests** -- Another class of precision
  experiments uses atoms (matter waves) to probe gravity and Lorentz
  symmetry. While many datasets are from single research groups (not
  large collaborations), their results are published for the community.
  For instance, atomic fountain interferometers have been used to test
  the universality of free fall and gravitational redshift at the
  quantum scale. A notable 2010 atom interferometry experiment measured
  the **gravitational redshift using atom "clock" frequencies**,
  confirming Einstein's prediction to within \$7\times10\^{-9}\$. Though
  not an anomaly, this supports that even quantum matter (atoms in
  superposition) obey classical space-time curvature rules. Other groups
  have compared atomic clock frequencies as Earth rotates to check for
  any preferred frame (testing Lorentz invariance in the matter sector);
  no daily variation has been seen beyond \$\sim10\^{-18}\$ relative
  precision, again **upholding standard relativity**. These results
  (often available via NIST or academic repositories) put stringent
  bounds on possible space-time structure effects -- e.g. any
  Lorentz-violating background field is constrained to an energy scale
  far beyond current reach. Upcoming projects (like the MAGIS-100 atomic
  interferometer and space-based clock networks) will generate open data
  to further test if gravity affects quantum coherence or if tiny
  space-time tremors can be observed. So far, **all such high-precision
  measurements agree with General Relativity and Lorentz symmetry**,
  giving no hint of breakdown -- but importantly they provide publicly
  scrutinizable evidence *for* the continuity and isotropy of space-time
  in regimes where new physics could have appeared.

**Quantum Optics Experiments: Fundamental Tests of Quantum Mechanics and
Space-Time**

- **Bell Test Experiments (Nonlocal Correlations)** -- Quantum optics
  experiments that test **Bell's inequality** probe whether nature has
  "hidden variables" bound by local realism (as in classical space-time)
  or truly nonlocal quantum entanglement. Decades of Bell tests -- many
  of which have publicly reported datasets or summaries -- have
  consistently violated Bell's inequality, supporting quantum mechanics
  over any local hidden-variable theory. Recent "loophole-free" Bell
  tests are especially relevant. For example, in 2015--2017, three
  separate experiments (in Delft, Vienna, and NIST) closed all major
  loopholes (detection efficiency, locality, freedom-of-choice). Data
  from these tests (published in *Nature* and made available in
  supplemental form) showed clear **violations of Bell's inequality with
  high confidence**, meaning that no classical mechanism in space-time
  (no slower-than-light signal or pre-set property) can explain the
  observed correlations. One remarkable Bell test used **ancient
  starlight and even quasars** to choose detector settings ("Cosmic Bell
  Test"). In that experiment, the random bit that determined how to
  measure each entangled photon was generated by a star's photon that
  had been en route for hundreds of years (or a quasar's photon billions
  of years) before the experiment. The resulting data still violated
  Bell's limit, pushing any potential "conspiracy" or local realist
  explanation back by **16 orders of magnitude in time**. In essence,
  even across vast distances and times, quantum entanglement holds --
  strongly suggesting that space-time separation does not weaken these
  correlations. Many of these Bell test datasets are publicly discussed
  (the cosmic test was reported in *Physical Review Letters* and MIT
  News, with method details open). The upshot is no **unexplained
  behavior** was found -- quantum theory triumphs -- and any theory of
  space-time that tries to be classical/local is severely constrained by
  these results.

- **Long-Distance Entanglement (Quantum Satellite Data)** -- Pushing
  entanglement to **record distances**, China's **QUESS "Micius"
  satellite** has generated datasets on photon pairs shared between
  ground stations thousands of kilometers apart. In 2017, the team
  distributed entangled photons to two observatories **1,203 km apart**
  and observed strong entanglement and Bell-inequality violation (S≈2.37
  \> 2) under strict locality conditions. This data (published in
  *Science*) demonstrated that entanglement persists over continental
  scales, with no observed decoherence or deviation that would hint at
  intermediate "space-time foam" effects. If space-time had a subtle
  structure causing entangled particles to lose correlation over long
  distances (as some quantum gravity models predict), the Micius results
  put upper limits on such effects. In fact, the photons' quantum
  correlations showed **no distance-dependent degradation** beyond
  expected loss from signal attenuation. This publicly reported
  experiment (and others like quantum teleports to orbit) suggest that
  **space-time is an accommodating stage for quantum phenomena even at
  large scales** -- no new space-time geometry effects (e.g. no "spooky"
  superluminal signal or dimming of entanglement) were needed to explain
  the observations, which matched standard quantum theory. The data from
  Micius and similar projects are often available through institutional
  repositories or upon request, and at least the summary results are
  openly accessible, serving as validation that *if* space-time has a
  foamy, grainy nature, it does not noticeably disrupt photonic
  entanglement up to these scales.

- **Delayed-Choice and Quantum Eraser Experiments** -- These experiments
  directly examine the role of measurement and the seemingly acausal
  correlations allowed by quantum mechanics. In John Wheeler's
  **delayed-choice experiment**, one decides *after* a particle passes a
  double-slit whether to observe an interference pattern or which-slit
  path -- essentially asking if present choices affect past events.
  Multiple realizations (using photons, atoms, even cosmic-scale setups)
  have produced data confirming quantum predictions: the outcome is as
  if the particle "knows" the experimental setup even when decided
  later, yet there is **no actual violation of causality**; rather,
  quantum theory forbids the particle from having determined path or
  wave behavior until measurement. For example, in 2007 Vincent Jacques
  *et al.* performed Wheeler's delayed choice with single photons and
  high-speed modulators, finding interference or particle-like
  detections in line with the delayed choice but with **no retroactive
  signal** -- thus, no classical cause-effect explanation can account
  for it. More recently (2023), a quantum eraser experiment (Kim & Ham,
  *Sci. Reports*) demonstrated that even when an entangled partner's
  information is erased **after** its twin hits a detector, interference
  can be restored in subsets of the data, seemingly **"violating"
  cause-effect ordering** yet still fully consistent with standard
  quantum mechanics. These results (often shared in open-access journals
  or arXiv) reinforce that **space-time in quantum experiments behaves
  non-classically**: quantum correlations can transcend straightforward
  temporal order. Crucially, however, no experiment has found evidence
  of actual information traveling backward in time or superluminally;
  rather, they highlight that our classical intuitions about separate
  space-time events break down in the quantum realm. The datasets from
  delayed-choice experiments (photon detection counts under various
  configurations) match quantum theoretical predictions exactly, and no
  "hidden" mechanism in space-time has been observed -- thereby
  challenging anyone proposing alternative space-time geometry models to
  reproduce these same quantum results without quantum theory's
  framework.

**Data Sources and Accessibility:** The above quantum optics experiments
are documented in **publicly available papers and archives**. For
instance, the **"Big Bell Test" (2018)** involved a global collaboration
(data described in *Nature* and on the project's website) where
human-generated random bits steered Bell tests in multiple labs -- all
outcomes consistent with quantum mechanics. The **Micius satellite
results** were published in *Science* (with the paper on arXiv for open
access). Foundational experiments like Aspect's 1982 Bell test, Tittel's
1998 18-km fiber test, and Zeilinger's 2007 delayed-choice all have
openly accessible reports as well. These serve as *reference datasets*
for anyone attempting to formulate novel space-time geometries: any
viable theory must account for the fact that **no anomalous violation of
quantum predictions or relativity has been empirically seen** in these
optical tests. The absence of unexplained behavior (within experimental
precision) itself is a valuable empirical datum constraining new
physics.

**Conclusion**

Across these domains -- high-energy collisions, ultra-sensitive
interferometry, and exquisite quantum optics tests -- **public
experimental data** is available to examine our current ideas of space
and time under extreme conditions. So far, this wealth of data has
largely **validated the standard theories** (quantum field theory and
general relativity) within their respective domains: no clear-cut
breakdown of Lorentz invariance, no detected space-time "pixelation,"
and quantum mechanics' bizarre nonlocality continues to hold robustly.
However, the **hints of anomalies** (like the muon *g-2* discrepancy or
long-standing puzzles in cosmology and quantum gravity not addressed
here) mean the door is open for new physics. The **public
accessibility** of these datasets -- from CERN's open collision records
to LIGO's gravitational wave archives and published quantum experiment
results -- empowers researchers everywhere to join the search. Any
proposed *novel space-time geometry* in the quantum realm can be put to
the test against these datasets: for example, does it allow tiny Lorentz
violations that should have shown up in 2.5 TeV LHC photons (and were
not)? Would it cause gravitational waves to disperse or arrive late
(ruled out to 1e-15 level)? Would it alter entanglement correlations
over 1200 km (observationally, it didn't)? By scrutinizing the
highlighted datasets and results, scientists can **validate or challenge
new theories of space-time** -- grounding speculative physics in
empirical reality.

**Sources:**

- CERN Open Data Portal -- LHC collision datasets (ATLAS/CMS); CMS
  extra-dimension (micro black hole) search results.

- LHC Lorentz invariance test (photon decay kinematics) -- Amram *et
  al.*, *Phys. Rev. Lett.* 132, 211801 (2024).

- Fermilab Muon *g-2* result (2021) -- Fermilab News Release.

- LIGO/Virgo GW170817 timing and Lorentz invariance -- *ApJL* 848:L13
  (2017).

- Fermilab Holometer findings -- symmetry magazine (2015).

- Modern Michelson--Morley optical experiments -- Wikipedia summary.

- Bell test with starlight (Cosmic Bell) -- MIT News (2017).

- 1200 km entanglement (Micius satellite) -- Yin *et al.*, *Science*
  356, 1140 (2017).

- Wheeler's delayed-choice experiments -- Wikipedia summary; Quantum
  eraser experiment (2023).
